# ===========================================
# LLM Provider Configuration
# ===========================================
# The tool checks for API keys in this order:
# 1. OPENAI_API_KEY (recommended)
# 2. GEMINI_API_KEY
# 3. OPENROUTER_API_KEY
# 4. LLM_API_BASE_URL (for local models)

# OpenAI (Recommended - checked first)
OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL=gpt-3.5-turbo

# Google Gemini (Alternative)
# GEMINI_API_KEY=your-gemini-api-key
# GEMINI_MODEL=gemini-2.5-pro-exp-03-25

# OpenRouter (Alternative)
# OPENROUTER_API_KEY=your-openrouter-key
# OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Generic OpenAI-compatible API (e.g., Ollama)
# LLM_API_BASE_URL=http://localhost:11434
# LLM_MODEL=llama2

# ===========================================
# Optional Settings
# ===========================================
# LOG_DIR=logs
